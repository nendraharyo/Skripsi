{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as proc\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "import random\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "import xgboost as xgb\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solusi 1 pake pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randompick(filename, s):\n",
    "    n = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)\n",
    "    skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "    df = pd.read_csv(filename, skiprows=skip)\n",
    "    return df\n",
    "\n",
    "dfb=randompick(r\"D:\\DatasetSkripsi\\Cleaned\\balanced-benign.csv\",3500000)\n",
    "dfd=randompick(r\"D:\\DatasetSkripsi\\Cleaned\\balanced-ddos.csv\",1500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dfb=dfb.replace('Benign',0)\n",
    "dfd=dfd.replace('ddos',1)\n",
    "le = proc.LabelEncoder()\n",
    "def labelencode(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == type(object):\n",
    "            print(column)\n",
    "            df[column] =le.fit_transform(df[column].astype(str))\n",
    "    return df\n",
    "dfb=labelencode(dfb)\n",
    "dfd=labelencode(dfd)\n",
    "df=pd.concat([dfb,dfd])\n",
    "dfb=0\n",
    "dfd=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    df.fillna(0,inplace=True)\n",
    "    df[df<0]=0\n",
    "    return df\n",
    "df=clean_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_dfbalanced=df.iloc[:,1:84]\n",
    "Y_dfbalanced=df.iloc[:,84]\n",
    "df=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "selector = SelectKBest(chi2, k = 10)\n",
    "cols = selector.get_support(indices=True)\n",
    "features_df_new = X_dfbalanced.iloc[:,cols]\n",
    "names = X_dfbalanced.columns.values[selector.get_support()]\n",
    "scores = selector.scores_[selector.get_support()]\n",
    "names_scores = list(zip(names, scores))\n",
    "ns_df = pd.DataFrame(data = names_scores, columns=['Feat_names', 'F_Scores'])\n",
    "ns_df_sorted = ns_df.sort_values(['F_Scores', 'Feat_names'], ascending = [False, True])\n",
    "print(ns_df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_dfbalanced=0\n",
    "X=features_df_new\n",
    "Y=Y_dfbalanced\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTime(a,b,c,d,e,f):\n",
    "    print(\"Waktu yang dibutuhkan dalam sekali training: \"+str(round(b-a))+\" detik\")\n",
    "    print(\"Waktu yang dibutuhkan dalam prediksi: \"+str(d-c)+\" detik\")\n",
    "    print(\"Waktu yang dibutuhkan dalam Cross Validation: \"+str(round(f-e))+\" detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "# evaluate predictions\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "skm.classification_report(y_test,lgbpred,output_dict=True, target_names=['Benign','ddos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "param = {\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 10}  # the number of classes that exist in this datset\n",
    "num_round = 20\n",
    "\n",
    "import time\n",
    "starttime = time.time()\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "endtime = time.time()\n",
    "\n",
    "print(endtime-starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preds = bst.predict(dtest)\n",
    "print(len(preds))\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print(best_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print(precision_score(y_test, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmodel = lgb.LGBMClassifier()\n",
    "a= time.time()\n",
    "lgbmodel.fit(X_train,y_train)\n",
    "b = time.time()\n",
    "\n",
    "\n",
    "c = time.time()\n",
    "lgbpred=lgbmodel.predict(X_test)\n",
    "d = time.time()\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "e = time.time()\n",
    "results = cross_val_score(lgbmodel, X, Y, cv=kfold)\n",
    "f = time.time()\n",
    "\n",
    "getTime(a,b,c,d,e,f)\n",
    "# evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "skm.classification_report(y_test,lgbpred,output_dict=True, target_names=['Benign','ddos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train=lgb.Dataset(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={}\n",
    "params['learning_rate']=0.03\n",
    "params['boosting_type']='gbdt' #GradientBoostingDecisionTree\n",
    "params['objective']='binary' #Binary target feature\n",
    "params['metric']='binary_logloss' #metric for binary classification\n",
    "params['max_depth']=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=lgb.train(params,d_train,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on the test set\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(precision_score(y_test, y_pred.round(), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = cat.CatBoostClassifier(\n",
    "    iterations=5, \n",
    "    learning_rate=0.1, \n",
    "    #loss_function='CrossEntropy'\n",
    ")\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train,\n",
    "        eval_set=(X_test, y_test), \n",
    "        verbose=False\n",
    ")\n",
    "\n",
    "print('CatBoost model is fitted: ' + str(clf.is_fitted()))\n",
    "print('CatBoost model parameters:')\n",
    "print(clf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catpred=clf.predict(data=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision_score(y_test, catpred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}